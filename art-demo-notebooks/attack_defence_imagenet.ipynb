{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic workflow with ART for evasion attacks and defences\n",
    "\n",
    "In this notebook we will show\n",
    "- how to work with a Keras image classifier in ART\n",
    "- how ART actually abstracts from the specific ML/DL backend\n",
    "- how to apply a Projected Gradient Descent (PGD) evasion attack against that classifier\n",
    "- how to deploy defences against such attacks\n",
    "- how to create adversarial samples that can bypass those defences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load prerequisites\n",
    "\n",
    "You can preinstall all prerequisites by uncommenting and running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet50 does not fit in GPU memory for the demo\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External installations\n",
    "!pip install git+https://github.com/nottombrown/imagenet_stubs Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load basic dependencies:\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load Keras dependencies:\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load ART dependencies:\n",
    "from art.classifiers import KerasClassifier\n",
    "from art.attacks import *\n",
    "from art.defences import *\n",
    "from art.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install ImageNet stubs\n",
    "import imagenet_stubs\n",
    "from imagenet_stubs.imagenet_2012_labels import name_to_label, label_to_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images\n",
    "\n",
    "We are going to load a set of 16 example images for illustration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list = list()\n",
    "\n",
    "for image_path in imagenet_stubs.get_image_paths():\n",
    "    im = image.load_img(image_path, target_size=(224, 224))\n",
    "    im = image.img_to_array(im)\n",
    "    images_list.append(im)\n",
    "\n",
    "images = np.array(images_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images all have a resolution of 224 x 224 pixels, and 3 color channels (RGB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of images:', images.shape[0])\n",
    "print('Dimension of images:', images.shape[1], 'x', images.shape[2], 'pixels')\n",
    "print('Number of color channels:', images.shape[3], '(RGB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As default choice, we are going to use the last image (`idx = 15`) for illustration purposes. <br>\n",
    "But you could use any other of the 16 images in the following (just change the value of the `idx` variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 15\n",
    "\n",
    "plt.figure(figsize=(8,8)); plt.imshow(images[idx] / 255); plt.axis('off'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ResNet50 classifier\n",
    "\n",
    "Next we are going to use a state-of-the-art classifier on those images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loads the pretrained ResNet50 model:\n",
    "model = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the prediction that this model yields for the selected image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to expand the input dimension and apply the preprocessing required for ResNet50:\n",
    "x = np.expand_dims(images[idx].copy(), axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "# Then apply the model, determine the predicted label and confidence:\n",
    "pred = model.predict(x)\n",
    "label = np.argmax(pred, axis=1)[0]\n",
    "confidence = pred[:,label][0]\n",
    "\n",
    "print('Prediction:', label_to_name(label), '- confidence {0:.2f}'.format(confidence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the model correctly tells us that this image shows a notebook computer, which is good :-)\n",
    "\n",
    "Next we will create an ART KerasClassifier wrapper around the model. <br>\n",
    "We need to take care of the `preprocess_input` logic that has to be applied:\n",
    "\n",
    "- swap the order of the color channels (RGB -> BGR)\n",
    "- subtract the channel means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the channel means as input for the ART KerasClassifier:\n",
    "mean_imagenet = np.array([103.939, 116.779, 123.68])\n",
    "\n",
    "# Create the classifier wrapper:\n",
    "classifier = KerasClassifier(clip_values=(0, 255), model=model, preprocessing=(mean_imagenet, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will apply the classifier object to obtain the prediction.\n",
    "\n",
    "**Note:** we have to swap the color channel order (from RGB to BGR) before feeding the input to the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as for the original model, we expand the dimension of the inputs.\n",
    "# We also swap the color channels (RGB -> BGR):\n",
    "x_art = np.expand_dims(images[idx], axis=0)[..., ::-1] \n",
    "\n",
    "# Then apply the model through the classifier API, determine the predicted label and confidence:\n",
    "pred = classifier.predict(x_art)\n",
    "label = np.argmax(pred, axis=1)[0]\n",
    "confidence = pred[:,label][0]\n",
    "\n",
    "print('Prediction:', label_to_name(label), '- confidence {0:.2f}'.format(confidence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So through the classifier API we obtain the same predictions as from the raw model, but now we have an abstraction from the actual backend (e.g. Keras).\n",
    "\n",
    "The classifier wrapper allows us to call other functions besides predict.\n",
    "\n",
    "For example, we can obtain the **loss gradient** of the classifier, which is used in many of the algorithms for adversarial sample generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_gradient = classifier.loss_gradient(x=x_art, y=to_categorical([label], nb_classes=1000))\n",
    "\n",
    "# Let's plot the loss gradient. \n",
    "# First, swap color channels back to RGB order:\n",
    "loss_gradient_plot = loss_gradient[0][..., ::-1] \n",
    "\n",
    "# Then normalize loss gradient values to be in [0,1]:\n",
    "loss_gradient_min = np.min(loss_gradient)\n",
    "loss_gradient_max = np.max(loss_gradient)\n",
    "loss_gradient_plot = (loss_gradient_plot - loss_gradient_min)/(loss_gradient_max - loss_gradient_min)\n",
    "\n",
    "# Show plot:\n",
    "plt.figure(figsize=(8,8)); plt.imshow(loss_gradient_plot); plt.axis('off'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create adversarial samples\n",
    "\n",
    "Next, we are going to create an adversarial sample. <br>\n",
    "We are going to use **Projected Gradient Descent (PGD)**, which is one of the strongest existing attacks. <br>\n",
    "We will first perform an **untargeted** adversarial attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the attacker:\n",
    "adv = ProjectedGradientDescent(classifier, targeted=False, max_iter=10, eps_step=1, eps=5)\n",
    "\n",
    "# Generate the adversarial sample:\n",
    "x_art_adv = adv.generate(x_art)\n",
    "\n",
    "# Plot the adversarial sample (note: we swap color channels back to RGB order):\n",
    "plt.figure(figsize=(8,8)); plt.imshow(x_art_adv[0][..., ::-1] / 255); plt.axis('off'); plt.show()\n",
    "\n",
    "# And apply the classifier to it:\n",
    "pred_adv = classifier.predict(x_art_adv)\n",
    "label_adv = np.argmax(pred_adv, axis=1)[0]\n",
    "confidence_adv = pred_adv[:, label_adv][0]\n",
    "print('Prediction:', label_to_name(label_adv), '- confidence {0:.2f}'.format(confidence_adv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will perform a **targeted attack** where we pick the class that we want the classifier to predict on the adversarial sample. <br>\n",
    "Below is the list of labels and class names - make your pick!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    print('label', i, '-', label_to_name(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As default, let's get this image misclassified as black swan (label 100)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's perform the targeted attack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the configuration to a targeted attack:\n",
    "adv.set_params(targeted=True)\n",
    "\n",
    "# Generate the adversarial sample:\n",
    "x_art_adv = adv.generate(x_art, y=to_categorical([target_label]))\n",
    "\n",
    "# Plot the adversarial sample (note: we swap color channels back to RGB order):\n",
    "plt.figure(figsize=(8,8)); plt.imshow(x_art_adv[0][..., ::-1] / 255); plt.axis('off'); plt.show()\n",
    "\n",
    "# And apply the classifier to it:\n",
    "pred_adv = classifier.predict(x_art_adv)\n",
    "label_adv = np.argmax(pred_adv, axis=1)[0]\n",
    "confidence_adv = pred_adv[:, label_adv][0]\n",
    "print('Prediction:', label_to_name(label_adv), '- confidence {0:.2f}'.format(confidence_adv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can measure the quantity of perturbation that was added to the image using different $\\ell_p$ norms. <br>\n",
    "**Note:** the PGD attack controls the $\\ell_\\infty$ norm via the `epsilon` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_0 = int(99*len(np.where(np.abs(x_art[0] - x_art_adv[0])>0.5)[0]) / (224*224*3)) + 1   \n",
    "l_1 = int(99*np.sum(np.abs(x_art[0] - x_art_adv[0])) / np.sum(np.abs(x_art[0]))) + 1\n",
    "l_2 = int(99*np.linalg.norm(x_art[0] - x_art_adv[0]) / np.linalg.norm(x_art[0])) + 1 \n",
    "l_inf = int(99*np.max(np.abs(x_art[0] - x_art_adv[0])) / 255) + 1\n",
    "\n",
    "print('Perturbation l_0 norm: %d%%' % l_0)\n",
    "print('Perturbation l_1 norm: %d%%' % l_1)\n",
    "print('Perturbation l_2 norm: %d%%' % l_2)\n",
    "print('Noise l_inf norm: %d%%' % l_inf)\n",
    "\n",
    "# Let's also plot the absolute amount of adversarial pixel perturbations:\n",
    "pert = np.abs(x_art[0] - x_art_adv[0])[..., ::-1]\n",
    "pert_min = np.min(pert)\n",
    "pert_max = np.max(pert)\n",
    "plt.figure(figsize=(8,8)); plt.imshow((pert - pert_min) / (pert_max - pert_min)); plt.axis('off'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply defences\n",
    "\n",
    "Next we are going to apply a simple input preprocessing defence: Spatial Smoothing. <br>\n",
    "Ideally, we want this defence to result in correct predictions when applied both to the original and the adversarial images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize the SpatialSmoothing defence. \n",
    "ss = SpatialSmoothing(window_size=3)\n",
    "\n",
    "# Apply the defence to the original input and to the adversarial sample, respectively:\n",
    "x_art_def, _ = ss(x_art)\n",
    "x_art_adv_def, _ = ss(x_art_adv)\n",
    "\n",
    "# Compute the classifier predictions on the preprocessed inputs:\n",
    "pred_def = classifier.predict(x_art_def)\n",
    "label_def = np.argmax(pred_def, axis=1)[0]\n",
    "confidence_def = pred_def[:, label_def][0]\n",
    "\n",
    "pred_adv_def = classifier.predict(x_art_adv_def)\n",
    "label_adv_def = np.argmax(pred_adv_def, axis=1)[0]\n",
    "confidence_adv_def = pred_adv_def[:, label_adv_def][0]\n",
    "\n",
    "# Print the predictions:\n",
    "print('Prediction of original sample:', label_to_name(label_def), '- confidence {0:.2f}'.format(confidence_def))\n",
    "print('Prediction of adversarial sample:', label_to_name(label_adv_def), \n",
    "      '- confidence {0:.2f}'.format(confidence_adv_def))\n",
    "\n",
    "# Show the preprocessed adversarial sample:\n",
    "plt.figure(figsize=(8,8)); plt.imshow(x_art_adv_def[0][..., ::-1] / 255); plt.axis('off'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform adaptive whitebox attack to defeat defences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are going to mount an adaptive whitebox attack in which the attacker aims at defeating the defence that we just put into place.\n",
    "\n",
    "First, we create a classifier which incorporates the defence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_def = KerasClassifier(defences=[ss], clip_values=(0, 255), \n",
    "                                 model=model, preprocessing=(mean_imagenet, 1))\n",
    "\n",
    "# Now we apply this classifier to the adversarial sample from before:\n",
    "pred_def = classifier_def.predict(x_art_adv)\n",
    "label_def = np.argmax(pred_def, axis=1)[0]\n",
    "confidence_def = pred_def[:, label_def][0]\n",
    "\n",
    "print('Prediction:', label_to_name(label_def), '- confidence {0:.2f}'.format(confidence_def))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that this classifier reproduces the prediction that we had obtained before by manually applying the input preprocessing defence.\n",
    "\n",
    "Now we create an adversarial sample against the *defended* classifier. <br>\n",
    "As we are going to see, this adversarial sample is able to bypass the input preprocessing defence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the attacker.\n",
    "# Note: here we are using a stronger attack (larger number of iterations) in order to defeat the defence\n",
    "adv_def = ProjectedGradientDescent(classifier_def, targeted=True, max_iter=40, eps_step=1, eps=5)\n",
    "\n",
    "# Generate the adversarial sample:\n",
    "x_art_adv_def = adv_def.generate(x_art, y=to_categorical([target_label]))\n",
    "\n",
    "# Plot the adversarial sample (note: we swap color channels back to RGB order):\n",
    "plt.figure(figsize=(8,8)); plt.imshow(x_art_adv_def[0][..., ::-1] / 255); plt.axis('off'); plt.show()\n",
    "\n",
    "# And apply the classifier to it:\n",
    "pred_adv = classifier_def.predict(x_art_adv_def)\n",
    "label_adv = np.argmax(pred_adv, axis=1)[0]\n",
    "confidence_adv = pred_adv[:, label_adv][0]\n",
    "print('Prediction:', label_to_name(label_adv), '- confidence {0:.2f}'.format(confidence_adv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also look at the $\\ell_p$ norms of that adversarial perturbation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_0 = int(99*len(np.where(np.abs(x_art[0] - x_art_adv_def[0])>0.5)[0]) / (224*224*3)) + 1   \n",
    "l_1 = int(99*np.sum(np.abs(x_art[0] - x_art_adv_def[0])) / np.sum(np.abs(x_art[0]))) + 1\n",
    "l_2 = int(99*np.linalg.norm(x_art[0] - x_art_adv_def[0]) / np.linalg.norm(x_art[0])) + 1 \n",
    "l_inf = int(99*np.max(np.abs(x_art[0] - x_art_adv_def[0])) / 255) + 1\n",
    "\n",
    "print('Perturbation l_0 norm: %d%%' % l_0)\n",
    "print('Perturbation l_1 norm: %d%%' % l_1)\n",
    "print('Perturbation l_2 norm: %d%%' % l_2)\n",
    "print('Noise l_inf norm: %d%%' % l_inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing with the previous adversarial sample, the $\\ell_0$ and $\\ell_1$ norms have slightly increased, while $\\ell_2$ and $\\ell_\\infty$ norms have stayed the same (the latter not being surprising as the PGD attack controls the $\\ell_\\infty$ norm budget)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "We have walked through an end-to-end example of using a Keras image classifier in ART, creating adversarial samples, deploying input preprocessing defences and, finally, bypassing those defences in an adaptive white-box attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
